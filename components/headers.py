def get_main_title():
    return """
    <h1> üß† Redes Neuronales para Predecir la Din√°mica de un Bal√≠n</h1>
    """

def get_intro_highlight():
    return """
    <div class="justified-text highlight">
    Este dashboard presenta el dise√±o, implementaci√≥n y evaluaci√≥n de modelos de deep learning 
    para predecir la trayectoria de un bal√≠n bajo un campo magn√©tico arm√≥nico.  
    La estructura y metodolog√≠as se basan en el documento del examen de desarrollo de proyectos.
    </div>
    """

def get_introduccion():
    return """
    <div class="justified-text margin-top-intro">
    Los sistemas ca√≥ticos, como el movimiento de un bal√≠n bajo la influencia de un campo magn√©tico,
    representan un reto en la predicci√≥n debido a su alta sensibilidad a condiciones iniciales.
    Este proyecto utiliza redes neuronales ‚Äîincluyendo arquitecturas LSTM, GRU y modelos densos‚Äî
    para modelar la din√°mica ca√≥tica a partir de datos experimentales.
    </div>
    """

def get_antecedentes():
    return """
    <div class="justified-text margin-top-antecedentes">
    La predicci√≥n de trayectorias en sistemas ca√≥ticos es complicada por la naturaleza no lineal y la sensibilidad a las condiciones iniciales. Los m√©todos tradicionales basados en ecuaciones diferenciales tienen limitaciones, lo que ha impulsado el uso de t√©cnicas de machine learning para capturar patrones complejos en datos experimentales.
    El problema se centra en predecir la trayectoria de un bal√≠n, cuyos datos experimentales comprenden 1020 puntos por muestra, con 195 muestras distribuidas en 5 carpetas (12G, 20G, 30G, 50G y 70G) y frecuencias entre 1Hz y 35Hz.
    <br><br>
    En este proyecto, adoptamos un enfoque basado en deep learning, comparando diferentes arquitecturas de redes neuronales.
    </div>
    """

def get_datos_experimentales():
    return """
    <div class="justified-text margin-top-intro">
    Los datos provienen de un experimento f√≠sico controlado y se estructuran de la siguiente forma:
    <ul>
      <li><strong style="color:#4b6cb7;">Total de muestras:</strong> 195 (35 por cada campo magn√©tico).</li>
      <li><strong style="color:#4b6cb7;">Puntos por muestra:</strong> 1020 registros de coordenadas (XM, YM).</li>
      <li><strong style="color:#4b6cb7;">Variables experimentales:</strong> Campo Magn√©tico (12G a 70G) y Frecuencia (1Hz a 35Hz).</li>
    </ul>
    <br>
    El preprocesamiento incluye:
    <ul>
      <li>Lectura y consolidaci√≥n de archivos txt (cada uno con 2 columnas: XM y YM).</li>
      <li>Extracci√≥n de metadatos (campo magn√©tico y frecuencia, a partir del nombre de carpeta y archivo).</li>
      <li>Normalizaci√≥n de los datos con la t√©cnica Min-Max, preservando la forma de la distribuci√≥n.</li>
      <li>Divisi√≥n del dataset en subconjuntos: entrenamiento (70%), validaci√≥n (20%) y prueba (10%).</li>
    </ul>
    </div>
    """

def get_section_header(num, icon, title):
    return f"""
    <div class="section-header"><h2>{icon} {num}. {title}</h2></div>
    """

def get_section_header_modelo(icon, title):
    return f"""
    <div class="section-header"><h2>{icon} {title}</h2></div>
    """

def get_arquitectura_modelo():
    return """
    <div class="justified-text margin-top-intro">
    Se evaluaron tres tipos de modelos:
    <ul>
      <li><strong style="color:#4b6cb7;">Redes LSTM:</strong> Ideales para capturar dependencias a largo plazo en series temporales.</li>
      <li><strong style="color:#4b6cb7;">Redes GRU:</strong> Variante de las LSTM con menor costo computacional.</li>
      <li><strong style="color:#4b6cb7;">Modelo Denso (Feedforward):</strong> Usado como referencia para comparar el desempe√±o.</li>
    </ul>
    <br>
    Para la red LSTM se configuraron dos capas con 80 y 29 neuronas, respectivamente, y para la GRU se utilizaron 62 y 47 neuronas.
    </div>
    """

def intro_highlight_modelo():
    return """
    <div class="justified-text highlight">
    Esta secci√≥n presenta el dise√±o, implementaci√≥n y evaluaci√≥n de tres tipos de arquitecturas 
    de redes neuronales utilizadas para modelar y predecir la din√°mica ca√≥tica del bal√≠n.
    El an√°lisis incluye los hiperpar√°metros √≥ptimos, la metodolog√≠a de entrenamiento y los resultados comparativos.
    </div>
    """

def get_arquitecturas():

    return """
    <div class="justified-text">
    Se evaluaron tres tipos diferentes de arquitecturas de redes neuronales, cada una con caracter√≠sticas 
    y ventajas espec√≠ficas para el modelado de sistemas din√°micos como el movimiento del bal√≠n:
    
    - **Redes LSTM (Long Short-Term Memory):** Dise√±adas espec√≠ficamente para capturar dependencias 
    temporales a largo plazo en series de tiempo, incorporando mecanismos de puertas que regulan el flujo 
    de informaci√≥n y permiten "recordar" patrones relevantes.
    
    - **Redes GRU (Gated Recurrent Unit):** Una variante optimizada de las LSTM que mantiene su 
    capacidad de modelar dependencias temporales pero con menor complejidad computacional, combinando 
    las puertas de olvido y entrada en una √∫nica estructura.
    
    - **Red Densa (Feedforward):** Utilizada como modelo base de comparaci√≥n, consiste en capas 
    totalmente conectadas que procesan la informaci√≥n de manera directa sin mecanismos de memoria expl√≠citos.
    </div>
    """

def get_hiperparametros():
    return """
    <div class="justified-text">
    Los hiperpar√°metros fueron optimizados mediante b√∫squeda aleatoria (Random Search), evaluando m√∫ltiples 
    combinaciones para encontrar la configuraci√≥n √≥ptima. Se implementaron estrategias como early stopping 
    para prevenir el sobreajuste y se ajustaron las tasas de aprendizaje para cada modelo.
    </div>
    """

def get_tarjeta_lstm():
    return """
    <div class="model-card">
        <div class="model-title">Modelo LSTM</div>
        <hr>
        <p><strong>Dropout:</strong> 0.226</p>
        <p><strong>Learning Rate:</strong> 0.006</p>
        <p><strong>Capas:</strong> [80, 29]</p>
        <p><strong>Optimizer:</strong> Adamax</p>
        <p><strong>Batch Size:</strong> 64</p>
        <p><strong>Epochs:</strong> 100 (con early stopping)</p>
    </div>
    """

def get_tarjeta_gru():
    return """
    <div class="model-card">
        <div class="model-title">Modelo GRU</div>
        <hr>
        <p><strong>Dropout:</strong> 0.41</p>
        <p><strong>Learning Rate:</strong> 0.0004</p>
        <p><strong>Capas:</strong> [62, 47]</p>
        <p><strong>Optimizer:</strong> Adamax</p>
        <p><strong>Batch Size:</strong> 32</p>
        <p><strong>Epochs:</strong> 100 (con early stopping)</p>
    </div>
    """

def get_tarjeta_densa():
    return """
    <div class="model-card">
        <div class="model-title">Modelo Denso</div>
        <hr>
        <p><strong>Dropout:</strong> 0.57</p>
        <p><strong>Learning Rate:</strong> 0.007</p>
        <p><strong>Capas:</strong> [56, 16, 11, 11]</p>
        <p><strong>Optimizer:</strong> Adamax</p>
        <p><strong>Batch Size:</strong> 128</p>
        <p><strong>Epochs:</strong> 80 (con early stopping)</p>
    </div>
    """

def get_proceso_train():
    return """
    <div class="justified-text">
    El proceso de entrenamiento sigui√≥ un enfoque riguroso para garantizar la robustez de los modelos:
    
    1. **Preparaci√≥n de datos**: Los datos se normalizaron para facilitar el entrenamiento y se dividieron en conjuntos de entrenamiento (70%), validaci√≥n (15%) y prueba (15%).
    
    2. **Flujo de datos**: Sedividieron los datos categoricamente por frecuencia y se escogio la media (media 10-15hz). Posteriormente se partio a la mitad las coordenadas, para implementar la primera mitad como entrada y la siguiente como salida
    
    3. **Regularizaci√≥n**: Se aplicaron t√©cnicas como dropout para prevenir el sobreajuste y se monitore√≥ la p√©rdida en el conjunto de validaci√≥n.
    
    4. **Early stopping**: Se configur√≥ un mecanismo de parada temprana con paciencia de 15 √©pocas para detener el entrenamiento cuando no hubiera mejora en la m√©trica de validaci√≥n.
    
    5. **Validaci√≥n cruzada**: Para garantizar la robustez de los resultados, los modelos se evaluaron utilizando validaci√≥n cruzada con 5 pliegues.
    </div>
    """

def get_inter_graficas():
    return """
        - **MSE (Error Cuadr√°tico Medio)**: Mide la diferencia cuadr√°tica promedio entre los valores predichos y reales. Menor es mejor.
        - **MAE (Error Absoluto Medio)**: Mide la diferencia absoluta promedio. Menor es mejor.
       
        **Conclusi√≥n**: La arquitectura LSTM tiene el "mejor" rendimiento con el menor error.
        """

def get_evaluacion_modelos():
    return """
    <div class="justified-text highlight">
    Esta secci√≥n presenta los resultados detallados del entrenamiento y evaluaci√≥n de los modelos de deep learning.
    Se incluyen visualizaciones interactivas del proceso de entrenamiento, predicciones en tiempo real y
    m√©tricas comparativas entre las distintas arquitecturas implementadas.
    </div>
    """